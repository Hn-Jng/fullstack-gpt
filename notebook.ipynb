{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Korea?'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import load_prompt\n",
    "from langchain.prompts import PromptTemplate, PipelinePromptTemplate\n",
    "\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "prompt.format(country = \"Korea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 37\u001b[0m\n\u001b[1;32m     17\u001b[0m start \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03mStart now!\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     26\u001b[0m final \u001b[38;5;241m=\u001b[39m PromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m{intro}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m pipeline_prompts \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 37\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintro\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43maa\u001b[49m),\n\u001b[1;32m     38\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m\"\u001b[39m, example),\n\u001b[1;32m     39\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m, start),\n\u001b[1;32m     40\u001b[0m ]\n\u001b[1;32m     42\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m PipelinePromptTemplate(\n\u001b[1;32m     43\u001b[0m     pipeline_prompts\u001b[38;5;241m=\u001b[39m pipeline_prompts,\n\u001b[1;32m     44\u001b[0m     final_prompt\u001b[38;5;241m=\u001b[39m final\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     47\u001b[0m chain \u001b[38;5;241m=\u001b[39m full_prompt \u001b[38;5;241m|\u001b[39m chat\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "intro = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "You are a role playing assistant.\n",
    "And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "This is an example of how you talk:\n",
    "\n",
    "Human: {example_question}\n",
    "You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Start now!\n",
    "\n",
    "Human: {question}\n",
    "You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "{intro}\n",
    "\n",
    "{example}\n",
    "\n",
    "{start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "pipeline_prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    pipeline_prompts= pipeline_prompts,\n",
    "    final_prompt= final\n",
    ")\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Groot\",\n",
    "        \"example_question\": \"What is your Name?\",\n",
    "        \"example_answer\": \"I am Groot\",\n",
    "        \"question\": \"What is your favorite food?\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
